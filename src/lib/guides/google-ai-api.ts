import type { Guide } from './types';

export const googleAiApi: Guide = {
    slug: 'google-ai-api',
    tag: 'GUIDE \u00B7 GOOGLE AI API',
    title: 'Google AI API: Bygg med Gemini',
    description: 'Komplett guide til Google AI API (Gemini API) for utviklere. LÃ¦r oppsett, autentisering, modellvalg og priser. Bygg AI-applikasjoner med multimodal input, grounding og context caching.',
    keywords: ['google ai api', 'gemini api', 'google gemini api', 'ai studio', 'gemini sdk', 'google ai norsk'],
    publishedDate: '2026-02-10',
    relatedSlugs: ['gemini', 'openai-api', 'anthropic-api'],
    category: 'bygg-med-ai',
    sections: [
        {
            heading: 'Hva er Google AI API?',
            content: 'Google AI API er Googles utviklerplattform for Gemini-modellene. Mens Gemini-appen p\u00e5 gemini.google.com er et ferdig chatprodukt, gir API-et deg direkte tilgang til modellene som programmerbare byggesteiner. Du kan sende tekst, bilder, video og lyd til modellene og bygge helt egne applikasjoner med AI-funksjonalitet. Alt fra smarte chatboter og dokumentanalyseverkt\u00f8y til bildeklassifisering og kodegeneratorer.\n\nHovedportalen for utviklere er ai.google.dev. Her finner du dokumentasjon, hurtigstartguider, referanser og kodeeksempler for alle Gemini-modellene. Google AI Studio p\u00e5 aistudio.google.com er det visuelle grensesnittet der du kan teste modellene direkte i nettleseren, eksperimentere med ulike parametere og generere API-n\u00f8kler uten \u00e5 skrive en eneste linje kode.\n\nDet er viktig \u00e5 forst\u00e5 forskjellen mellom Google AI API og Vertex AI. Google AI API (via ai.google.dev) er designet for utviklere og startups som vil komme raskt i gang. Det er enkelt oppsett med API-n\u00f8kler og et sj\u00f8ner\u00f8st gratisniv\u00e5. Vertex AI (via Google Cloud) er enterpriseplattformen med IAM-basert tilgangsstyring, VPC-nettverk, SLA-er og compliance-sertifiseringer. Modellene er de samme, men infrastrukturen rundt er forskjellig. For de aller fleste som starter ut, er Google AI API det riktige valget.'
        },
        {
            heading: 'Oppsett og autentisering',
            content: 'Det f\u00f8rste du trenger er en API-n\u00f8kkel. G\u00e5 til aistudio.google.com, logg inn med Google-kontoen din, og klikk p\u00e5 "Get API key". Du kan opprette en n\u00f8kkel knyttet til et nytt eller eksisterende Google Cloud-prosjekt. Hele prosessen tar under ett minutt, og du trenger ikke legge inn betalingsinformasjon for \u00e5 bruke gratisniv\u00e5et.\n\nN\u00e5r du har n\u00f8kkelen, installerer du den offisielle SDK-en. For JavaScript og TypeScript kj\u00f8rer du "npm install @google/genai". For Python bruker du "pip install google-genai". Google lanserte disse nye, forenklede SDK-pakkene i 2025, og de har erstattet de eldre pakkene @google/generative-ai og google-generativeai. De nye pakkene har et renere API med bedre st\u00f8tte for streaming, function calling og multimodal input.\n\nBeste praksis er \u00e5 lagre API-n\u00f8kkelen som en milj\u00f8variabel. Opprett en .env-fil med linjen GOOGLE_AI_API_KEY=din-n\u00f8kkel-her, og legg .env i .gitignore slik at n\u00f8kkelen ikke havner p\u00e5 GitHub. I koden leser du n\u00f8kkelen med process.env.GOOGLE_AI_API_KEY. I produksjon bruker du hemmelighetsh\u00e5ndtering i skyplattformen din, som Vercel Environment Variables eller Google Cloud Secret Manager.\n\nHvis du senere trenger enterprise-funksjoner som finkornet tilgangsstyring eller dataisolering, kan du migrere til Vertex AI uten \u00e5 endre modellkallene. SDK-en st\u00f8tter begge backends, s\u00e5 overgangen er smertefri.'
        },
        {
            heading: 'Ditt f\u00f8rste API-kall med Gemini',
            content: 'Her er et enkelt eksempel i JavaScript. F\u00f8rst importerer du GoogleGenAI fra @google/genai. S\u00e5 oppretter du en klientinstans med API-n\u00f8kkelen din. Deretter kaller du client.models.generateContent med modellnavnet, for eksempel "gemini-2.5-flash", og en tekstprompt. Svaret finner du i response.text. Det er bokstavelig talt fire linjer kode for \u00e5 f\u00e5 et svar fra en av verdens mest avanserte AI-modeller.\n\nFor streaming, som gir en mye bedre brukeropplevelse i sanntidsapplikasjoner, bruker du generateContentStream i stedet. Da f\u00e5r du svaret chunk for chunk etter hvert som modellen genererer det, i stedet for \u00e5 vente p\u00e5 hele teksten. Dette er spesielt viktig for chatboter og interaktive grensesnitt der brukeren ser teksten bygge seg opp i sanntid.\n\nEt viktig konsept er tokens. En token er omtrent tre til fire tegn p\u00e5 norsk. B\u00e5de det du sender inn og det modellen svarer med telles. Gemini-modellene har ekstremt store kontekstvinduer. Gemini 2.5 Pro st\u00f8tter opptil en million tokens input, noe som betyr at du kan sende med hundrevis av sider med dokumenter i en enkelt foresp\u00f8rsel. Hold system-instruksjonen konsis og bruk maxOutputTokens-parameteren for \u00e5 kontrollere lengden p\u00e5 svarene.\n\nDu kan ogs\u00e5 sende med en systemInstruction-parameter som setter konteksten for samtalen, tilsvarende system-meldingen i OpenAI API. Bruk den til \u00e5 definere chatbotens personlighet, spr\u00e5k og oppf\u00f8rsel. For eksempel: "Du er en norskspraklig kundeserviceassistent for Nettbutikken AS. Svar alltid h\u00f8flig og konsist."'
        },
        {
            heading: 'Modeller og priser',
            content: 'Gemini 2.5 Pro er flaggskipmodellen og en av de sterkeste AI-modellene p\u00e5 markedet i 2026. Den utmerker seg p\u00e5 kompleks resonnering, koding, matematikk og analyse av store dokumenter. Med et kontekstvindu p\u00e5 en million tokens kan den behandle enorme mengder informasjon. I gratisniv\u00e5et f\u00e5r du et begrenset antall foresp\u00f8rsler per dag. I betalingsniv\u00e5et koster den 1,25 dollar per million input-tokens og 10 dollar per million output-tokens for foresp\u00f8rsler under 200 000 tokens.\n\nGemini 2.5 Flash er den raske og kostnadseffektive modellen. Den er designet for oppgaver som krever h\u00f8y gjennomstr\u00f8mming og lav latens, som sanntidschat, klassifisering og enklere tekstbehandling. Flash-modellen har ogs\u00e5 resonneringsevner via en "thinking"-modus og st\u00f8tter en million tokens kontekst. Prisen er betydelig lavere: 0,15 dollar per million input-tokens og 0,60 dollar per million output-tokens i standardmodus. Dette gj\u00f8r den til en av de billigste avanserte modellene p\u00e5 markedet.\n\nDet som gj\u00f8r Google AI API spesielt attraktivt for utviklere er det sj\u00f8ner\u00f8se gratisniv\u00e5et. Du kan bruke b\u00e5de Gemini 2.5 Pro og Flash helt gratis, med begrensninger p\u00e5 antall foresp\u00f8rsler per minutt og per dag. For hobbyprosjekter, prototyping og sm\u00e5 applikasjoner er gratisniv\u00e5et ofte mer enn nok. Ingen andre store AI-leverand\u00f8rer tilbyr like kraftige modeller uten krav om betalingsinformasjon.\n\nGoogle tilbyr ogs\u00e5 Gemini 2.0 Flash for de som trenger en ekstra rask modell, samt eldre modeller som Gemini 1.5 Pro og Flash til reduserte priser. Embeddings-modellen text-embedding-004 er tilgjengelig for vektors\u00f8k og RAG-l\u00f8sninger. Du finner oppdatert prisinformasjon p\u00e5 ai.google.dev/pricing.'
        },
        {
            heading: 'Avanserte funksjoner',
            content: 'Multimodal input er der Gemini virkelig skiller seg ut. Du kan sende bilder, video, lyd og PDF-er direkte i API-kallet sammen med tekst. Last opp et bilde og be modellen beskrive det, analyser en video og f\u00e5 en oppsummering, eller send en lydfil og f\u00e5 en transkripsjon. Gemini kan ogs\u00e5 behandle flere modaliteter samtidig. For eksempel kan du sende et bilde av en kvittering sammen med teksten "trekk ut bel\u00f8pet og datoen" og f\u00e5 strukturert data tilbake.\n\nGrounding med Google S\u00f8k er en kraftig funksjon som lar Gemini hente fersk informasjon fra nettet for \u00e5 underbygge svarene sine. N\u00e5r du aktiverer grounding, vil modellen automatisk s\u00f8ke p\u00e5 Google n\u00e5r det er relevant, og inkludere referanser i svaret. Dette reduserer hallusinasjoner dramatisk og gj\u00f8r modellen nyttig for sp\u00f8rsm\u00e5l om aktuelle hendelser, priser og annen informasjon som endrer seg ofte. Ingen andre store API-leverand\u00f8rer har like tett integrasjon mellom s\u00f8kemotor og AI-modell.\n\nContext caching lar deg lagre store mengder kontekst som du bruker gjentatte ganger, slik at du slipper \u00e5 sende det p\u00e5 nytt med hver foresp\u00f8rsel. Hvis du for eksempel har et stort dokument som mange brukere stiller sp\u00f8rsm\u00e5l om, kan du cache dokumentet \u00e9n gang og bare betale for input-tokens den f\u00f8rste gangen. Etterf\u00f8lgende foresp\u00f8rsler mot den cachede konteksten er betydelig billigere. Dette er uvurderlig for RAG-l\u00f8sninger og dokumentanalyse i stor skala.\n\nCode execution er en innebygd funksjon der Gemini kan skrive og kj\u00f8re Python-kode for \u00e5 l\u00f8se oppgaver som krever beregninger, dataanalyse eller visualisering. Modellen genererer kode, kj\u00f8rer den i et sandkassemilj\u00f8, og returnerer resultatet. Dette er spesielt nyttig for matematiske problemer, databehandling og generering av grafer. I tillegg st\u00f8tter API-et function calling for \u00e5 la modellen samhandle med dine egne systemer og API-er, p\u00e5 samme m\u00e5te som OpenAI sin function calling.'
        },
        {
            heading: 'Google AI API vs. OpenAI vs. Anthropic',
            content: 'De tre store API-leverand\u00f8rene har ulike styrker, og valget avhenger av hva du bygger. Google AI API skinner med multimodal input, det enorme kontekstvinduet p\u00e5 en million tokens, grounding med Google S\u00f8k, og det sj\u00f8ner\u00f8se gratisniv\u00e5et. Hvis du trenger \u00e5 analysere store dokumenter, behandle video og lyd, eller bygge en prototype uten \u00e5 betale noe som helst, er Gemini det naturlige valget.\n\nOpenAI API har det st\u00f8rste \u00f8kosystemet og flest tredjepartsintegrasjoner. GPT-5 og o3-modellene er sterke p\u00e5 resonnering og koding, og function calling og structured outputs er velmodne funksjoner. OpenAI har ogs\u00e5 det st\u00f8rste utviklerfellesskapet, s\u00e5 du finner flest eksempler, guider og biblioteker. Velg OpenAI hvis du trenger det bredeste \u00f8kosystemet og de mest kamptestede API-ene.\n\nAnthropic API med Claude-modellene er kjent for n\u00f8yaktighet, sikkerhet og lange kontekstvinduer. Claude er spesielt sterk p\u00e5 koding, analyse og oppgaver som krever forsiktig resonnering. Anthropic fokuserer tungt p\u00e5 AI-sikkerhet, noe som gir trygge og p\u00e5litelige svar. Velg Anthropic hvis n\u00f8yaktighet og sikkerhet er toppprioritet.\n\nEn smart strategi er \u00e5 ikke l\u00e5se seg til \u00e9n leverand\u00f8r. Vercel AI SDK (ai-sdk.dev) lar deg bytte mellom Google, OpenAI og Anthropic med \u00e9n linje kode. Start med Google AI API for prototyping takket v\u00e6re gratisniv\u00e5et, test med flere leverand\u00f8rer for \u00e5 finne den beste modellen for din spesifikke oppgave, og optimaliser prisen i produksjon. Alle tre plattformene forbedrer seg raskt, s\u00e5 det som er best i dag kan endre seg i morgen.'
        }
    ]
};
