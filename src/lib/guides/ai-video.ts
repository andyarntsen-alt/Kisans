import type { Guide } from './types';

export const aiVideo: Guide = {
    slug: 'ai-video',
    tag: 'GUIDE \u00B7 AI-VIDEO',
    title: 'Lag videoer med AI: Runway, Sora og HeyGen',
    description: 'Komplett guide til AI-videogenerering i 2026. Lær å lage videoer med Runway, Sora og HeyGen \u2013 med praktiske prompt-tips, prissammenligning og råd om rettigheter.',
    keywords: ['ai video', 'runway ai', 'sora openai', 'heygen', 'lag video med ai', 'ai video norsk', 'text to video', 'ai videogenerering', 'kling ai', 'video fra tekst'],
    publishedDate: '2026-02-10',
    relatedSlugs: ['bildegenerering', 'ai-verktoy-2026', 'prompting'],
    category: 'kreativitet',
    sections: [
        {
            heading: 'AI-video i 2026',
            content: 'AI-videogenerering har utviklet seg enormt de siste årene. I 2024 var det fortsatt en nyhet at AI kunne lage korte, sammenhengende videoklipp fra tekst. I 2026 kan du generere videoer med realistiske bevegelser, konsistent fysikk og detaljerte scener \u2013 alt fra en enkel tekstbeskrivelse. Teknologien brukes allerede i reklame, sosiale medier, e-l\u00e6ring og filmprototyping.\n\nHovedakt\u00f8rene er Runway (pioneren innen kreativ AI-video), Sora fra OpenAI (kjent for fotorealistisk kvalitet), og HeyGen (spesialisert p\u00e5 AI-avatarer og talende videoer). I tillegg finnes kinesiske alternativer som Kling fra Kuaishou og Vidu fra Shengshu, som begge leverer imponerende resultater til lavere pris.\n\nDet er verdt \u00e5 forst\u00e5 at AI-video i dag fungerer best for korte klipp p\u00e5 5\u201330 sekunder. Du kan ogs\u00e5 bruke bilde-til-video (animere et stillbilde) og video-til-video (endre stil p\u00e5 eksisterende video). For lengre produksjoner kombinerer de fleste flere klipp i et vanlig redigeringsprogram.'
        },
        {
            heading: 'Runway: For kreative profesjonelle',
            content: 'Runway (runwayml.com) har v\u00e6rt en forgjenger innen AI-video helt siden de var med p\u00e5 utviklingen av Stable Diffusion. Gen-3 Alpha, lansert sommeren 2024, var et stort sprang i kvalitet med bedre bevegelser og konsistens. Runway har siden oppdatert modellene sine med forbedret fysikksimulering, lengre klipp og h\u00f8yere oppl\u00f8sning. Plattformen st\u00f8tter tekst-til-video, bilde-til-video og video-til-video, i tillegg til verkt\u00f8y som motion brush (styr bevegelse i spesifikke omr\u00e5der) og kamerakontroll.\n\nRunways styrke er det kreative \u00f8kosystemet. Grensesnittet er bygget for videoskapere og gir deg finkornet kontroll over kamerabevegelser, overganger og stil. Du kan bruke referansebilder for \u00e5 styre estetikken, og du f\u00e5r forholdvis konsistente resultater selv over flere genereringer. Runway har ogs\u00e5 et bredt utvalg av AI-verkt\u00f8y for etterbehandling, inkludert bakgrunnsfjerning, fargejustering og bildeforst\u00f8rrelse.\n\nRunway opererer med et kredittbasert system. Standard-planen koster 12 dollar i m\u00e5neden og inkluderer 625 kreditter. Pro-planen til 28 dollar gir 2250 kreditter og tilgang til de nyeste modellene med h\u00f8yere oppl\u00f8sning. Unlimited til 76 dollar gir ubegrenset generering i relaxed-modus. Et videosekund koster typisk 5\u201310 kreditter avhengig av oppl\u00f8sning og modell, s\u00e5 Standard-planen gir deg rundt 1\u20132 minutter med video i m\u00e5neden.'
        },
        {
            heading: 'Sora: OpenAIs videogenerator',
            content: 'Sora (sora.com) ble f\u00f8rst vist frem av OpenAI i februar 2024 med imponerende demoer som satte en ny standard for AI-video. Etter en lang venteperiode ble Sora lansert for offentligheten i desember 2024. Modellen skiller seg ut med realistisk fysikk, naturlig bevegelse og evnen til \u00e5 generere komplekse scener med flere objekter som samhandler p\u00e5 en troverdig m\u00e5te.\n\nSora er integrert i ChatGPT-\u00f8kosystemet. Du f\u00e5r tilgang gjennom ChatGPT Plus (20 dollar i m\u00e5neden) med et begrenset antall genereringer, eller gjennom ChatGPT Pro (200 dollar i m\u00e5neden) med betydelig mer kapasitet og h\u00f8yere oppl\u00f8sning. Sora st\u00f8tter ogs\u00e5 bilde-til-video, video-remixing og storyboard-funksjoner der du kan planlegge en sekvens av scener.\n\nSoras sterke side er fotorealisme og naturlige bevegelser. Hvis du trenger videoer som ser ut som ekte filmopptak \u2013 for eksempel en drone som flyr over et landskap eller en person som g\u00e5r gjennom en gate \u2013 leverer Sora sv\u00e6rt overbevisende resultater. Begrensningene inkluderer tidvis inkonsistens i lengre klipp, og modellen kan fortsatt sl\u00e5 feil med detaljer som fingre og tekst. Genereringshastigheten kan ogs\u00e5 v\u00e6re treg i perioder med h\u00f8y etterspørsel.'
        },
        {
            heading: 'HeyGen: AI-avatarer og stemmekloning',
            content: 'HeyGen (heygen.com) skiller seg fra Runway og Sora ved \u00e5 fokusere p\u00e5 talende videoer med AI-avatarer. I stedet for \u00e5 generere scener fra tekst, lager HeyGen videoer der en digital person snakker til kamera. Du skriver manuset, velger en avatar (eller lager en basert p\u00e5 deg selv), og f\u00e5r en ferdig video med leppe\u00adssynkronisert tale p\u00e5 over 40 spr\u00e5k \u2013 inkludert norsk.\n\nBruksomr\u00e5dene er mange: oppl\u00e6ringsvideoer, produktpresentasjoner, personlige videomeldinger, og flerspr\u00e5klig innhold der du kan \u00aboverdube\u00bb deg selv til andre spr\u00e5k med bevart stemme og munnobjekter. Instant Avatar lar deg lage en tilpasset avatar basert p\u00e5 et kort videoopptak av deg selv, mens du ogs\u00e5 kan klone stemmen din for et mer autentisk resultat.\n\nHeyGen har en gratis plan med begrensede funksjoner. Creator-planen koster 29 dollar i m\u00e5neden og gir deg tilgang til alle standard-avatarer, stemmekloning og opptil 15 minutter med video. Business-planen til 89 dollar inkluderer Instant Avatar, prioritert prosessering og mer videotid. For bedrifter finnes Enterprise med tilpassede avtaler. HeyGen er spesielt popul\u00e6rt blant markedsf\u00f8rere og e-l\u00e6ringsselskaper som trenger skalerbart videoinnhold uten tradisjonell videoproduksjon.'
        },
        {
            heading: 'Slik skriver du gode videoprompts',
            content: 'Videoprompts fungerer annerledes enn bildeprompts fordi du m\u00e5 beskrive bevegelse og tid i tillegg til det visuelle. Et godt videoprompt har tre hovedelementer: scenen (hva som er i bildet), handlingen (hva som skjer) og stilen (hvordan det skal se ut). V\u00e6r s\u00e5 spesifikk som mulig \u2013 \u00abEn golden retriever l\u00f8per gjennom en eng med vilde blomster i solnedgang, h\u00e5ndholdfilmet kamera med lett ust\u00f8 bevegelse\u00bb gir mye bedre resultat enn \u00abEn hund p\u00e5 en eng\u00bb.\n\nKamerabevegelse er en viktig del av videoprompts. Spesifiser om kameraet skal panorere (sveipe sidelengs), tilte (bevege opp eller ned), zoome inn eller ut, eller f\u00f8lge motivet. Begreper som \u00abdrone-shot\u00bb, \u00abf\u00f8rstepersons perspektiv\u00bb, \u00abslowmotion\u00bb og \u00abtimelapse\u00bb er effektive for \u00e5 styre resultatet. I Runway kan du ogs\u00e5 bruke innebygde kamerakontroller for enda mer presisjon.\n\nFor best resultat, start med et referansebilde. Bilde-til-video gir nesten alltid mer forutsigbare resultater enn ren tekst-til-video. Generer f\u00f8rst et bilde med Midjourney, DALL-E eller et annet bildegenereringsverkt\u00f8y, og bruk det som startpunkt for videoen. Eksperimenter med korte klipp f\u00f8rst (3\u20135 sekunder) for \u00e5 finne riktig stil og stemning, og utvid deretter til lengre sekvenser n\u00e5r du er forn\u00f8yd.'
        },
        {
            heading: 'Rettigheter og etisk bruk',
            content: 'Rettighetene til AI-generert video varierer mellom plattformene. Runway gir deg fulle kommersielle rettigheter p\u00e5 betalte planer. OpenAI gir deg ogs\u00e5 rett til \u00e5 bruke Sora-generert innhold kommersielt gjennom ChatGPT Plus og Pro. HeyGen gir kommersielle rettigheter p\u00e5 alle betalte planer. Likevel b\u00f8r du alltid sjekke de oppdaterte brukervilk\u00e5rene, da de kan endre seg.\n\nDeepfakes er den st\u00f8rste etiske utfordringen med AI-video. Teknologien gj\u00f8r det mulig \u00e5 lage realistiske videoer av personer som sier eller gj\u00f8r ting de aldri har gjort. Alle seri\u00f8se plattformer har retningslinjer mot misbruk, og mange legger inn usynlige vannmerker (som C2PA-metadata) i genererte videoer for \u00e5 gj\u00f8re det mulig \u00e5 identifisere AI-innhold. Bruk aldri AI-video til \u00e5 etterligne ekte personer uten deres samtykke.\n\nEU AI Act, som gradvis trer i kraft fra 2025 til august 2026, stiller krav om at AI-generert innhold skal merkes tydelig. Dette gjelder b\u00e5de video, bilder og lyd. For norske bedrifter og innholdsskapere betyr dette at du m\u00e5 v\u00e6re \u00e5pen om at innholdet er AI-generert, spesielt i kommersielle sammenhenger. Flere sosiale medier-plattformer krever ogs\u00e5 allerede merking av AI-generert innhold. Det tryggeste er \u00e5 alltid merke AI-generert video, uansett plattform.'
        }
    ]
};
